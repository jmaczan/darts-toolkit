# Educational DARTS implementation

We build a thing that uses gradient descent to find an architecture of a cell. Cell is an architecture of a neural network, a repeatable block of network's computation. We can stack multiple cells on top of each other to build a deeper network. A cell consists of several nodes, connected with edges. A node stores cell's parameters, at every stage of computation. So, the first node stores input features. Intermediate nodes store hidden parameters. The last node stores network's output. Nodes are connected with edges. Initially - at the beginning of architecture search - all nodes are connected to all preceeding nodes. When architecture search is finished, each edge is exactly a single operation (like 3x3 convolution, 3x3 max pooling etc.). But during the search, each edge holds multiple operations at once. It's called Mixed Operation. 